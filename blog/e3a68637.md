---
title: ETL工具Kettle调研报告
description: ETL工具Kettle调研报告
published: true
date: '2024-08-01T02:01:07.000Z'
dateCreated: '2024-08-01T02:01:07.000Z'
tags: 大数据
editor: markdown
---

Kettle，全称为 Pentaho Data Integration（PDI），是一个开源的 ETL（Extract, Transform, Load，提取、转换、加载）工具。Kettle 最早由 Matt Casters 在 2001 年创建，最初只是一个用于数据集成的小工具。2006 年，Pentaho 公司收购了 Kettle，并将其整合为 Pentaho BI Suite 的一部分，正式更名为 Pentaho Data Integration。Kettle 以其灵活的图形界面和强大的数据处理能力而闻名，支持多种数据源和目标，并提供丰富的插件来扩展其功能。该工具适用于数据迁移、数据仓库构建和数据清洗等场景，是企业级数据集成解决方案的理想选择。

<!-- more -->

## 特点

Kettle 具有以下主要特点：

- **开源和免费**：作为开源软件，Kettle 不仅免费，而且可以通过社区获得广泛的支持和资源。
- **图形化界面**：Kettle 提供了一个用户友好的图形化界面（Spoon），用户可以通过拖放操作轻松设计和管理 ETL 流程。
- **跨平台支持**：Kettle 基于 Java 开发，可以在多种操作系统上运行，包括 Windows、Linux 和 Mac OS。
- **丰富的数据源支持**：Kettle 支持多种数据源，包括关系型数据库（如 MySQL、PostgreSQL、Oracle）、NoSQL 数据库（如 MongoDB）、文件（如 CSV、Excel）、云服务（如 Amazon S3、Google Cloud Storage）等。
- **扩展性强**：Kettle 允许用户通过编写插件来扩展其功能，支持自定义步骤和任务。
- **大数据集成**：Kettle 与 Hadoop 生态系统集成良好，支持 HDFS、Hive、HBase、MapReduce 等技术，适用于大数据处理。

## 应用场景

Kettle 广泛应用于各种数据集成和数据仓库建设项目中，包括但不限于：

- **数据迁移**：将数据从一个系统迁移到另一个系统，通常在系统升级或更换时使用。
- **数据清洗**：处理和清理原始数据，去除冗余和错误数据，提高数据质量。
- **数据同步**：定期更新多个系统之间的数据，确保数据的一致性和完整性。
- **商业智能**：为 BI 系统准备和转换数据，为报表和数据分析提供支持。

#### 优缺点

###### 优点

1. **使用门槛低**：仅需简单的学习，非专业开发人员也可掌握诸多 ETL（Extract, Transform, Load）作业的构建、测试、运行。
2. **组件支持丰富**：Kettle 支持的组件极为丰富，从数据输入、输出到数据转换，它都有支持，用户还可以通过自定义脚本和插件来扩展它的功能。
3. **性能表现优异**：作业运行的性能和资源消耗较好。经性能测试，千万条 Excel 数据导入数据库仅需不到 7 分钟，资源使用 1 核 CPU 和 6G 内存。
4. **跨平台支持**：Kettle 是基于 Java 开发的，可以在 Windows、Linux、macOS 等多种操作系统上运行，提供了较好的跨平台兼容性。
5. **图形化界面**：提供直观的图形化用户界面（GUI），使用户可以通过拖拽组件、连接步骤来设计 ETL 流程，降低了开发难度。

###### 缺点

1. **复杂场景处理有限**：对于复杂的 ETL 场景，Kettle 的图形化界面可能不够灵活，需要编写复杂的脚本或自定义插件来实现。
2. **学习曲线**：虽然入门容易，但要完全掌握 Kettle 的高级功能和最佳实践，仍需要一定的学习和实践时间。
3. **社区和文档支持有限**：前些年 Kettle 在 ETL 工具领域大行其道，但随着近几年其他 ETL 工具的发展和 Pentaho 运营策略的变更，Kettle 的维护和发展变得不再积极。网上对于 Kettle 的教程资料大多集中在 2015-2022 年之间，随后的年份资料、文档较少。

## 竞品分析

#### 前言

面对小数据量、批处理、性能效率要求不严格的应用场景，选择一个功能丰富、上手难度低且开源免费的 ETL 工具尤为重要。下面将对 Kettle、Nifi、DataX、Canal 四种 ETL 工具进行对比分析，阐述为什么选择 Kettle。

#### 工具介绍

###### Kettle

Kettle，又称为 Pentaho Data Integration (PDI)，是一个开源的 ETL 工具。它支持图形化界面，允许用户通过拖拽组件来设计数据流。Kettle 支持多种数据源和目标，包括关系数据库、文件系统、云服务等。其主要特点包括：

- **图形化设计**：用户可以使用图形化界面轻松设计复杂的数据转换流程。
- **丰富的组件**：Kettle 提供了大量的内置组件，用于数据提取、转换和加载。
- **可扩展性**：支持用户自定义插件，满足特定需求。
- **社区支持**：由于其开源性质，有广泛的社区支持和文档资源。

###### NiFi

Apache NiFi 是一个强大的数据集成工具，专为数据流自动化设计。它提供了一个基于 Web 的用户界面，允许用户实时监控和管理数据流。NiFi 的主要特点包括：

- **数据流管理**：支持数据的实时采集、转换和传输。
- **可视化界面**：用户可以通过拖拽组件来设计和管理数据流。
- **扩展性和灵活性**：支持多种数据源和目标，并且可以通过自定义处理器扩展功能。
- **安全和审计**：提供细粒度的权限控制和全面的审计日志。

###### DataX

DataX 是阿里巴巴开源的一款数据同步工具，旨在实现高效的数据传输和转换。主要用于大数据平台之间的数据同步。DataX 的主要特点包括：

- **高效性**：针对海量数据传输进行了优化，能够高效地进行数据同步。
- **多数据源支持**：支持多种数据源和目标，包括关系数据库、NoSQL 数据库、文件系统等。
- **易用性**：配置简单，用户只需编写 JSON 格式的配置文件即可实现数据同步。
- **社区和文档**：提供详细的文档和社区支持，方便用户上手。

###### Canal

Canal 是阿里巴巴开源的一个数据库增量订阅和消费的工具。它主要用于解决 MySQL 数据库的增量数据订阅和消费需求。Canal 的主要特点包括：

- **实时性**：能够实时捕获 MySQL 数据库的变更数据。
- **高效性**：采用 MySQL 主从复制的协议，性能优越。
- **灵活性**：支持多种数据消费模式，可以与 Kafka、RocketMQ 等消息队列集成。
- **开源和社区支持**：作为开源工具，有广泛的社区支持和丰富的文档资源。

#### 工具对比

| 维度           | Kettle                                                                                                                                                                                                               | Nifi                                                          | DataX                                                      | Canal                                                             |
| -------------- | -------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------- | ------------------------------------------------------------- | ---------------------------------------------------------- | ----------------------------------------------------------------- |
| 上手难度       | 容易                                                                                                                                                                                                                 | 中等                                                          | 困难                                                       | 困难                                                              |
|                | Kettle 提供了直观的图形用户界面，适合初学者快速上手。                                                                                                                                                                | Nifi 虽然有可视化界面，但需要理解其复杂的数据流模型。         | DataX 需要掌握较多的配置和脚本编写，学习曲线较陡。         | Canal 主要用于 MySQL 增量订阅和消费，对数据库知识要求较高。       |
| 可视化程度     | 高                                                                                                                                                                                                                   | 高                                                            | 低                                                         | 低                                                                |
|                | Kettle 有丰富的图形界面和图表来展示 ETL 流程。                                                                                                                                                                       | Nifi 也提供了图形化界面，可以直观地设计和监控数据流。         | DataX 主要通过配置文件和命令行操作，缺乏直观的图形界面。   | Canal 主要通过日志和命令行监控，缺少可视化支持。                  |
| 是否支持中文   | 是                                                                                                                                                                                                                   | 否                                                            | 是                                                         | 是                                                                |
|                | Kettle 提供完整的中文文档和界面支持。                                                                                                                                                                                | Nifi 主要为英文界面和文档，需要较好的英文水平。               | DataX 有丰富的中文文档和社区支持。                         | Canal 也有中文文档和支持。                                        |
| ETL 功能丰富度 | 高                                                                                                                                                                                                                   | 中等                                                          | 高                                                         | 低                                                                |
|                | Kettle 提供了全面的 ETL 功能，包括数据清洗、转换和加载。                                                                                                                                                             | Nifi 更侧重于数据流处理，ETL 功能相对单一。                   | DataX 支持多种数据源和目标，提供强大的数据迁移和同步功能。 | Canal 主要用于 MySQL 数据的增量订阅，ETL 功能较弱。               |
| 性能           | 中等                                                                                                                                                                                                                 | 中等                                                          | 高                                                         | 高                                                                |
|                | Kettle 的性能在中等水平，适合中小规模数据处理。                                                                                                                                                                      | Nifi 的性能也在中等水平，适合实时数据流处理。                 | DataX 在大数据量的迁移和同步上表现优异。                   | Canal 在 MySQL 增量数据订阅和消费上性能高效。                     |
| 容错和恢复能力 | 低                                                                                                                                                                                                                   | 高                                                            | 高                                                         | 高                                                                |
|                | Kettle 的容错和恢复能力相对较弱，需要手动干预。                                                                                                                                                                      | Nifi 具有良好的容错和恢复机制，自动重试和回滚功能强大。       | DataX 提供了完善的容错和恢复机制，确保数据传输的可靠性。   | Canal 能够稳定地处理 MySQL 增量数据，容错和恢复能力强。           |
| 监控日志支持   | 低                                                                                                                                                                                                                   | 高                                                            | 中等                                                       | 低                                                                |
|                | Kettle 的监控和日志功能相对简单。                                                                                                                                                                                    | Nifi 提供详细的监控和日志记录，便于排查问题。                 | DataX 提供一定的监控和日志支持，但需要手动配置。           | Canal 的监控和日志支持较为基础。                                  |
| 分布式集群支持 | 低                                                                                                                                                                                                                   | 高                                                            | 高                                                         | 高                                                                |
|                | Kettle 对分布式集群支持较差，可采用多节点负载均衡。                                                                                                                                                                  | Nifi 原生支持分布式集群，适合大规模数据处理。                 | DataX 支持分布式集群，适合大规模数据迁移和同步。           | Canal 可以在分布式环境中部署，适合大规模 MySQL 数据处理。         |
| 适应场景       | 批处理、数据集成、数据仓库                                                                                                                                                                                           | 实时数据流处理、大数据                                        | 数据迁移、同步                                             | MySQL 增量订阅和消费                                              |
|                | Kettle 适合批量数据处理、数据集成和数据仓库建设。                                                                                                                                                                    | Nifi 专注于实时数据流处理和大数据应用，适合流式数据处理场景。 | DataX 专长于数据迁移和同步，适合多种数据源的对接。         | Canal 主要用于 MySQL 数据库的增量订阅和消费，适合数据库变更监控。 |
| 国内社区活跃度 | 中等                                                                                                                                                                                                                 | 低                                                            | 高                                                         | 高                                                                |
|                | Kettle 在国内有一定的用户群和社区支持，但不如 DataX 和 Canal 活跃。                                                                                                                                                  | Nifi 在国内社区较为冷清，主要在国外使用较多。                 | DataX 在国内有活跃的社区和用户群，广泛用于数据迁移和同步。 | Canal 在国内有广泛的应用和社区支持，尤其在 MySQL 场景下。         |
| 开源协议       | Apache License 2.0                                                                                                                                                                                                   | Apache License 2.0                                            | Apache License 2.0                                         | Apache License 2.0                                                |
|                | 所有工具均采用 Apache License 2.0 开源协议。该协议允许用户自由使用、修改和分发软件，包括在商业环境中使用，无需支付费用。用户可以根据需要修改源代码，并将修改后的版本用于商业用途，但必须保留原始版权声明和协议条款。 |                                                               |                                                            |                                                                   |
| 出品方         | Hitachi Vantara (原 Pentaho)                                                                                                                                                                                         | Apache                                                        | 阿里巴巴                                                   | 阿里巴巴                                                          |
|                | Kettle 由 Hitachi Vantara（原 Pentaho）开发。                                                                                                                                                                        | Nifi 由 Apache 基金会管理和维护。                             | DataX 由阿里巴巴开发，专注于数据迁移和同步。               | Canal 由阿里巴巴开发，专注于 MySQL 增量数据的订阅和消费。         |

#### 为什么选择 Kettle

1. **上手难度**：

    - **容易**：Kettle 提供了直观的图形用户界面，用户可以通过拖拽和配置方式完成数据处理工作，无需编写复杂的代码。这使得初学者可以快速上手，显著降低了学习成本。
2. **可视化程度**：

    - **高**：Kettle 拥有丰富的图形界面和图表来展示 ETL 流程，用户可以通过图形化的方式设计数据处理流程，直观展示 ETL 流程的每一步骤，便于理解和维护。
3. **是否支持中文**：

    - **是**：Kettle 提供完整的中文界面和文档，降低了中文用户的使用门槛，便于在国内推广和应用。
4. **ETL 功能丰富度**：

    - **高**：Kettle 提供了全面的 ETL 功能，包括数据清洗、转换和加载，支持多种数据源和目标，能够满足复杂的业务需求。
5. **性能**：

    - **中等**：虽然 Kettle 的性能在中等水平，但对于中小规模的数据处理任务来说已经足够。其丰富的功能和易用性在实际应用中常常能带来更高的效率。
6. **容错和恢复能力**：

    - **低**：尽管 Kettle 的容错和恢复能力相对较弱，需要手动干预，但是对于非关键任务或中小规模的数据处理任务，这一点可以通过严格的流程管理和监控来弥补。
7. **监控日志支持**：

    - **低**：Kettle 的监控和日志功能相对简单，但也提供了一定的日志记录和调试工具，用户可以通过这些工具实时查看数据流动情况，快速定位和解决问题。
8. **分布式集群支持**：

    - **低**：虽然 Kettle 对分布式集群支持较差，但对于中小规模的数据处理任务，其单机模式已经足够，且配置和维护更为简单。且可采用多节点负载均衡的方式来提高服务的可用性，缓解生产压力。
9. **适应场景**：

    - **批处理、数据集成、数据仓库**：Kettle 适合用于批量数据处理、数据集成和数据仓库建设，能够高效地执行数据抽取、转换和加载任务，支持广泛的数据源和目标。
10. **国内社区活跃度**：

    - **中等**：Kettle 在国内有一定的用户群和社区支持，用户可以通过社区获得支持和帮助，分享经验和最佳实践。
11. **开源协议**：

    - **Apache License 2.0**：Kettle 采用 Apache License 2.0 开源协议，用户可以自由使用、修改和分发软件，包括在商业环境中使用，无需支付费用。
12. **出品方**：

    - **Hitachi Vantara (原 Pentaho)**：Kettle 由 Hitachi Vantara（原 Pentaho）开发，背靠强大的企业背景，具有良好的支持和发展前景。

## 核心组件

Kettle 的核心组件包括 Spoon、Pan、Kitchen 和 Carte。下面是对这些组件的详细介绍及其作用与关系：

#### Spoon

![](https://lbs-images.oss-cn-shanghai.aliyuncs.com/202504260203504.png)

**作用：**

Spoon 是 Kettle 的图形化用户界面工具，用于开发和设计 ETL 作业和转换。用户可以通过 Spoon 创建、编辑和测试 ETL 流程。

**功能：**

- **图形化设计**：通过拖放操作，用户可以方便地设计数据流和转换。
- **调试和测试**：提供调试工具，可以在设计阶段测试和调整 ETL 流程。
- **连接管理**：配置和管理数据源连接，如数据库、文件、Web 服务等。
- **插件支持**：支持各种插件扩展功能，满足不同数据处理需求。

#### Carte

![](https://lbs-images.oss-cn-shanghai.aliyuncs.com/202504260203514.png)

**作用：**

Carte 是 Kettle 的轻量级 Web 服务器，用于分布式执行和监控 ETL 任务。它允许在分布式环境下运行转换和作业，并提供 Web 界面进行监控和管理。

**功能：**

- **分布式执行**：支持在多台服务器上分布式执行 ETL 任务，提高处理效率。
- **远程管理**：通过 Web 界面远程监控和管理 ETL 任务的执行状态。
- **负载均衡**：可以配置多台 Carte 服务器进行负载均衡，处理大规模数据任务。

#### Pan

**作用：**

Pan 是 Kettle 的命令行工具，用于执行转换（Transformation）。它是一个轻量级的运行时引擎，专门用于执行由 Spoon 设计的转换。

**功能：**

- **批处理**：适合在批处理作业中使用，通过命令行或脚本执行转换。
- **自动化**：可以集成到自动化任务中，如定时任务、脚本或其他调度工具。
- **独立执行**：无需图形界面，适合在服务器环境中运行。

#### Kitchen

**作用：**

Kitchen 是 Kettle 的命令行工具，用于执行作业（Job）。作业通常包含多个转换和其他控制流程，如条件判断、循环等。

**功能：**

- **调度执行**：通过命令行或脚本执行作业，实现定时调度和自动化处理。
- **控制流程**：管理复杂的 ETL 流程，包括执行多个转换、条件分支、循环和错误处理。
- **任务集成**：适合与其他调度系统或脚本集成，进行大规模数据处理任务。

#### 组件间的关系

1. **Spoon**：作为设计工具，用户通过 Spoon 创建和编辑转换（Transformation）和作业（Job），并将其保存为 Kettle 的文件格式（.ktr 和.kjb）。
2. **Pan**：作为执行引擎，用于命令行方式执行 Spoon 设计的转换文件（.ktr）。
3. **Kitchen**：作为执行引擎，用于命令行方式执行 Spoon 设计的作业文件（.kjb）。
4. **Carte**：作为分布式服务器，可以远程执行和监控由 Spoon 设计的转换和作业，通过 Web 接口管理 ETL 任务。

这些组件共同构成了 Kettle 的完整 ETL 解决方案，支持从设计、开发到执行和监控的全流程数据处理。

## 系统架构

![](https://lbs-images.oss-cn-shanghai.aliyuncs.com/202504260204594.png)

## 调度流程

1. 开发人员首先在 Windows 机器上使用图形化界面工具 Spoon 通过拖拉拽的方式创建、编辑和测试 ETL 转换或者作业。
2. ETL 作业开发测试完毕后，将作业保存到存储于 MySQL 的资源库中（需进行账号密码认证）。
3. 登录 Xxl-job 调度平台进行任务配置，传入作业路径、作业运行节点（也可通 Nginx 负载均衡随机）、作业运行时间及频次等参数。
4. Xxl-job 调度平台根据任务配置参数向 Carte 集群中指定节点发送执行 ETL 作业的 http 请求（需进行账号密码认证）。
5. Carte 集群中接收到执行 ETL 作业 http 请求的节点查询 MySQL 资源库中的作业信息，随后开始任务执行。
6. 开发人员可通过 Carte 自带的 web 页面启动、停止作业，或者查看作业执行情况，包含作业状态、作业日志、作业运行时间等详细信息（需进行账号密码认证）。
7. 为方便 ETL 作业提交到 Carte 集群后各节点可方便的操作文件，遂需采用 NAS 存储。
8. 除了通过 Xxl-job 调度平台提交作业到 Carte 集群，还可直接通过 Spoon 提交作业到 Carte 集群，并且此种方式相较于前者可以设置作业分布式运行在 Carte 集群的各个节点中。即 Spoon 设置 Carte 集群中的一台节点为 master、其他节点为 node，提交作业到 Carte 集群后，即可将作业分片到多个 node 节点并行运行，对于一些需要大量资源的任务可采用此种方式。但需要注意的是，master 节点存在单点故障问题，目前没有找到 master 节点高可用的方案。且 Xxl-job 调度平台提交作业到 Carte 集群的方式，无法达到此种效果，即无法将作业并行在各节点运行。

## 性能测试

[Kettle（Pentaho Data Integration）性能测试报告](https://juejin.cn/spost/7397683842633449523 "https://juejin.cn/spost/7397683842633449523")

## 现存问题

1. 由于 Spoon 是 Java 语言编写的 GUI 工具，开发体验不是很好。在使用 Spoon 进行 ETL 作业的构建、测试、运行时可能偶尔会遇到卡顿、响应慢的情况，只能通过调整 JVM 参数给与更大的内存进行缓解。
2. Kettle 对分布式集群的支持较差，通过 Xxl-job 调度中心 http 请求调度作业的方式暂无法让作业分布式运行到各个 Carte 节点，以便吃到多个 Carte 节点的资源。想要让作业分布式运行到各个 Carte 节点，暂时只能通过 Spoon 直接提交作业到 Carte 集群中才可以。对于分布式运行作业的 Master 节点的高可用问题，目前还没有可行方案。所以，暂时最好的作业提交方案还是通过 xxl-job 调度到 Carte 集群中的指定一个节点运行，虽无法让一个作业利用多个节点的资源，但解决了高可用的问题。一个 Carte 节点挂掉，还可提交作业到其他节点。
3. Kettle 在执行 ETL 作业时，如果某个节点宕机，作业无法自动恢复。这意味着在节点恢复正常之前，所有依赖该节点的任务都会中断，影响了数据处理的连续性和稳定性。Kettle 缺少内置的自动重试机制，任务失败后需要人工干预重新启动，这在处理大规模数据时尤为不便。
4. Kettle 的日志功能相对简单，提供的信息不够详尽，难以快速定位和解决问题。尤其在复杂的数据处理流程中，缺乏详细的日志会增加排查问题的难度。Carte 提供的 web 页面功能较为简陋，且任务调度记录会在 carte 服务器重启后丢失暂。时不能确认是 Carte 本身问题，还是安装配置问题。
5. Kettle 缺乏强大的实时监控功能，不能实时捕捉和展示 ETL 流程中的状态变化，用户只能通过手动刷新或查看日志文件了解作业状态。

## 资源

#### 项目源代码

[pentaho-kettle](https://github.com/pentaho/pentaho-kettle.git)

#### 项目安装包

[pdi-ce-9.2.0.0-290.zip](https://privatefilesbucket-community-edition.s3.us-west-2.amazonaws.com/9.2.0.0-290/ce/client-tools/pdi-ce-9.2.0.0-290.zip)